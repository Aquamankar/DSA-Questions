kafka topics wise study and revision 


 Kafka Basics & Architecture
What is Kafka and when to use it

Kafka vs traditional message brokers (RabbitMQ, ActiveMQ)

Kafka components:

Producer

Consumer

Topic

Partition

Broker

Cluster

Zookeeper (older) / KRaft (newer)

Log-based storage concept

Pull vs Push in Kafka

2. Topics & Partitions
Topic creation and naming conventions

Partitions for scalability

Partition leader and replicas

Replication factor

How Kafka ensures fault tolerance

How consumers know which partition to read from

3. Producers
Producer API basics

Producer acknowledgments (acks=0, 1, all)

Message keys and partitioning strategy

Batching and compression (gzip, snappy, lz4, zstd)

Idempotent producers

Producer retries and delivery guarantees

4. Consumers & Consumer Groups
Consumer API basics

Consumer group concept

Offset management (auto vs manual commit)

Rebalance events and how they work

Consumer lag

Poll mechanism (poll() method)

Static vs dynamic group membership

--------------------++++++++++++++++++++-------------------------------------

Static vs Dynamic Group Membership

Dynamic Membership (default)

When a consumer joins, Kafka assigns it a new member ID.

On restart â†’ it gets a new ID, so Kafka rebalances.

Frequent restarts = frequent rebalances = bad performance.

Static Membership

Consumer keeps a fixed identity (via group.instance.id).

On restart â†’ Kafka remembers the consumerâ€™s partition assignment â†’ avoids full rebalance.

Much more stable for production workloads.

Config Example:

group.instance.id=my-consumer-1


(Each consumer must have a unique group.instance.id).

Benefit:

Reduces downtime.

Useful for long-lived applications where consumers restart often.

ðŸ”¹ Interview Questions

What is consumer lag? How do you monitor it?

Why does Kafka use a poll-based model instead of push?

What happens if a consumer doesnâ€™t call poll() in time?

Whatâ€™s the difference between max.poll.records and max.poll.interval.ms?

What is static membership in Kafka consumer groups?

What problem does static membership solve compared to dynamic membership?

Can two consumers in the same group have the same group.instance.id?

ðŸ‘‰ Do you want me to now extend the Kafka_Consumer.md file with:

Consumer basics + groups (previous answer)
_------_------------------_---;;;;;-_---:---------_----_-------__-----_-------
Consumer lag
Consumer lag = Difference between the latest offset in a partition (what the producer has written) and the offset last committed/read by the consumer.

In other words, it tells how far behind the consumer is compared to the producer.

ðŸ‘‰ Formula:

Consumer Lag = Latest Offset (Log End Offset) - Consumerâ€™s Current Offset


_------------------------------------------------_-----------------

Poll mechanism

Static vs dynamic membership

so youâ€™ll have one consolidated file for Kafka consumer interview prep?

--------------------------------------+++++++-------------------------&

5. Kafka Message Delivery Semantics
At-most-once

At-least-once

Exactly-once semantics (EOS)


-----------------------------------------------------------------------


1. At-most-once

Meaning: A message is delivered zero or one time. No retries. If it fails once, itâ€™s lost forever.

When it happens in Kafka:

Producer sends message without retries or acknowledgments (acks=0).

Consumer commits offset before processing the record (so if crash happens after commit â†’ message lost).

Use case: Low-value, high-speed data like metrics, logs where losing a few records doesnâ€™t matter.

Configuration:

Producer: acks=0, enable.idempotence=false.

Consumer: Commit offsets before processing messages.

ðŸ”¹ 2. At-least-once

Meaning: A message is delivered one or more times. No data loss, but duplicates are possible.

When it happens in Kafka:

Producer retries on failure (acks=all with retries enabled).

Consumer commits offset after processing (so no loss, but on crash message may reprocess â†’ duplicate).

Use case: Financial transactions, billing systems, where data loss is unacceptable but duplicates can be handled.

Configuration:

Producer: acks=all, enable.idempotence=false, retries > 0.

Consumer: Commit offsets only after successful processing.

ðŸ”¹ 3. Exactly-once (EOS)

Meaning: Each message is processed only once â†’ no loss, no duplicates.

How Kafka achieves this:

Idempotent producer: (enable.idempotence=true) ensures producer retries do not create duplicates.

Transactions: (transactional.id on producer) allows a group of messages across topics/partitions to be atomic.

Consumer offsets are stored as part of the same transaction â†’ ensures "read-process-write" occurs exactly once.

Use case: Payments, order systems, stock trades where duplicates/loss are unacceptable.

Configuration:

Producer:

enable.idempotence=true
transactional.id=my-tx-id
acks=all


Consumer: Use transactional-aware consumers with isolation.level=read_committed.

âœ… Summary:

At-most-once: Fastest, possible loss, no duplicates.

At-least-once: Reliable, possible duplicates.

Exactly-once: Reliable and no duplicates (heavier).

Would you like me to also draw a diagram showing how producer + broker + consumer interact in each case (so you can use it for interview answers)?
------------------------------------_--------------------------------------

How Kafka achieves each

6. Kafka Storage & Retention
Log segment files

Retention policies:

Time-based retention

Size-based retention

Log compaction

How Kafka handles old messages

7. Kafka Streams & KSQL
Kafka Streams API

Stateless vs stateful processing

Windowing in streams

KSQL basics for streaming queries

8. Kafka Connect
Source connectors (e.g., MySQL â†’ Kafka)

Sink connectors (e.g., Kafka â†’ Elasticsearch)

Standalone vs distributed mode

Common connectors and configs

9. Kafka Security
Authentication (SASL, Kerberos, SSL)

Authorization (ACLs)

Encryption in-transit (TLS)

10. Kafka in Production
Monitoring metrics (through JMX, Prometheus)

Common operational issues:

High consumer lag

Under-replicated partitions

Leader imbalance

Scaling Kafka clusters

Backup & disaster recovery

Schema management with Confluent Schema Registry (Avro, JSON, Protobuf)

âœ… Common Kafka Interview Questions

Explain Kafkaâ€™s architecture in detail.

How does Kafka achieve fault tolerance?

How do you ensure exactly-once message processing?

What is consumer lag and how do you reduce it?

How does partitioning affect message ordering?

How do you secure a Kafka cluster?

If you want, I can prepare you a Kafka Interview Quick Revision Sheet with 50+ questions and short bullet answers, so you can go through them like flashcards before an interview. That format works really well for last-minute prep.












